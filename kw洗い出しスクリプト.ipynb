{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "XkPAYr2742oD",
        "dgxuBapbS1vz",
        "3pkGZDV1op9L",
        "SXxB8idQUghG",
        "SRFyCWr8cnSC"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cinnamonmeal0/books_scraping/blob/main/kw%E6%B4%97%E3%81%84%E5%87%BA%E3%81%97%E3%82%B9%E3%82%AF%E3%83%AA%E3%83%97%E3%83%88.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 準備\n",
        "---\n",
        "#### まず初めにこのセルを実行してください。実行完了してからでないとエラーが出てしまいます。\n"
      ],
      "metadata": {
        "id": "_3cXXBaVrXIz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uyamDJVIp317",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36294ede-817b-4deb-8a0d-792ab7642d4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.10/dist-packages (4.18.1)\n",
            "Requirement already satisfied: urllib3[socks]<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from selenium) (2.0.7)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.10/dist-packages (from selenium) (0.24.0)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.10/dist-packages (from selenium) (0.11.1)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2024.2.2)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from selenium) (4.10.0)\n",
            "Requirement already satisfied: attrs>=20.1.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (23.2.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.6)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.2.0)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.10/dist-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
            "Requirement already satisfied: google-colab-selenium in /usr/local/lib/python3.10/dist-packages (1.0.12)\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.10/dist-packages (from google-colab-selenium) (4.18.1)\n",
            "Requirement already satisfied: urllib3[socks]<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from selenium->google-colab-selenium) (2.0.7)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.10/dist-packages (from selenium->google-colab-selenium) (0.24.0)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.10/dist-packages (from selenium->google-colab-selenium) (0.11.1)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium->google-colab-selenium) (2024.2.2)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from selenium->google-colab-selenium) (4.10.0)\n",
            "Requirement already satisfied: attrs>=20.1.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium->google-colab-selenium) (23.2.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium->google-colab-selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium->google-colab-selenium) (3.6)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium->google-colab-selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium->google-colab-selenium) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium->google-colab-selenium) (1.2.0)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.10/dist-packages (from trio-websocket~=0.9->selenium->google-colab-selenium) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium->google-colab-selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium->google-colab-selenium) (0.14.0)\n"
          ]
        }
      ],
      "source": [
        "# 必要なライブラリなどインストール\n",
        "! pip install beautifulsoup4\n",
        "! pip install selenium\n",
        "! pip install google-colab-selenium"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "duplication_set = set()"
      ],
      "metadata": {
        "id": "fnXP7XM_LzOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_last_parenthesis_index(text):\n",
        "  \"\"\"\n",
        "  文字列の最後尾が)または）であれば、(または（が前から何番目かを取得する関数\n",
        "\n",
        "  Args:\n",
        "    text: 処理対象の文字列\n",
        "\n",
        "  Returns:\n",
        "    (または（が前から何番目か、または-1 (最後尾に)または）がない場合)\n",
        "  \"\"\"\n",
        "\n",
        "  # 最後尾が)か）かをチェック\n",
        "  if text.endswith(\")\") or text.endswith(\"）\"):\n",
        "    # 最後尾が)の場合\n",
        "    if text.endswith(\")\"):\n",
        "      return text.rfind(\"(\")\n",
        "    # 最後尾が）の場合\n",
        "    else:\n",
        "      return text.rfind(\"（\")\n",
        "  else:\n",
        "    return -1\n",
        "\n",
        "def check_duplicate(text):\n",
        "  # 正規表現で【】とその中のテキストを削除\n",
        "  text = re.sub(r'【.+?】', '', text)\n",
        "  text = re.sub(r'《.+?》', '', text)\n",
        "  text = re.sub(r'［.+?］', '', text)\n",
        "  text = re.sub(r'●.+?●', '', text)\n",
        "  text = re.sub(r'＜.+?＞', '', text)\n",
        "  # 最後尾に()があるかチェックし、あれば削除\n",
        "  index = find_last_parenthesis_index(text)\n",
        "  if index != -1:\n",
        "    text = text[:index]\n",
        "  return text\n",
        "\n",
        "def delete_unnecessary_words(book_title):\n",
        "  # 不要ワードはここに追加する\n",
        "  unnecessary_words = [\"分冊版\", \"フルカラー\", \"単話\", \"THE COMIC\", \"上\", \"下\", \"vol.1\", \"act.1\", \"連載版\"]\n",
        "\n",
        "  for word in unnecessary_words:\n",
        "    if word in book_title:\n",
        "      print(book_title)\n",
        "      book_title = book_title.replace(word, \"\")\n",
        "\n",
        "  # スペースが重複している場合は一つにまとめる\n",
        "  book_title = \" \".join(book_title.split())\n",
        "\n",
        "  return book_title\n"
      ],
      "metadata": {
        "id": "ZRv49wyYdDz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### これより下記のセルは1つずつ順番に実行してください。処理が終わるまで次のセルを実行しないでください。\n",
        "何かエラーが起きて実行できないときは、Slack(@Nozomi Sugaya)まで、エラーの内容(コピペで大丈夫です)含めて連絡お願いします。"
      ],
      "metadata": {
        "id": "h8GIvKfV7cut"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### コミックシーモア 上位20位取得\n",
        "---\n"
      ],
      "metadata": {
        "id": "J2QVwBVj4MOl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "\n",
        "cmoa_data_to_insert = []\n",
        "\n",
        "get_dict = {\"少女マンガ\":\"genre/?id=20\", \"女性マンガ\":\"genre/?id=2\", \"少年マンガ\":\"genre/?id=12\", \"青年マンガ\":\"genre/?id=13\", \"BLコミック\":\"genre/?id=24\", \"TLコミック\":\"genre/?id=34\",\"シーモア先行\":\"precede\", \"オリジナル\":\"original\", \"オトナコミック\":\"genre/?id=11\"}\n",
        "# スクレイピング対象の URL にリクエストを送り HTML を取得する\n",
        "for key,v in get_dict.items():\n",
        "  res = requests.get('https://www.cmoa.jp/search/purpose/ranking/' + v)\n",
        "\n",
        "  # レスポンスの HTML から BeautifulSoup オブジェクトを作る\n",
        "  soup = BeautifulSoup(res.text, 'html.parser')\n",
        "  print(\"------\")\n",
        "  print(\"【\"+ key + \"】\")\n",
        "  for k in range(20):\n",
        "      elems = soup.select(f'#ranking_result_list > li:nth-of-type({k + 1}) > div.search_result_box_right > div.search_result_box_right_sec1 > p > a')\n",
        "      if elems:\n",
        "          link = elems[0]['href']\n",
        "          full_path = \"https://www.cmoa.jp\" + link\n",
        "          text = elems[0].text.strip()\n",
        "          if text:\n",
        "              text = check_duplicate(text)\n",
        "              text = delete_unnecessary_words(text)\n",
        "              if text[:5] in [item[:5] for item in duplication_set] and text[-3:] in [item[-3:] for item in duplication_set]:\n",
        "                continue\n",
        "              print(text, full_path)\n",
        "              cmoa_data_to_insert.append([text, full_path,\"コミックシーモア上位20位\" + \"【\"+ key + \"】\"])\n",
        "              duplication_set.add(text)\n",
        "              # print(text)\n",
        "st.append_rows(values=cmoa_data_to_insert)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxPOgLxZp42f",
        "outputId": "be7db92e-8227-4a11-a961-10359b7ab2e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------\n",
            "【少女マンガ】\n",
            "傷モノの花嫁～虐げられた私が、皇國の鬼神に見初められた理由～ 分冊版\n",
            "------\n",
            "【女性マンガ】\n",
            "悪役令嬢レベル99 ～私は裏ボスですが魔王ではありません～ https://www.cmoa.jp/title/209389/\n",
            "元夫から「ロミオメール」が届いた件について https://www.cmoa.jp/title/263136/\n",
            "ヤンデレ魔法使いは石像の乙女しか愛せない 魔女は愛弟子の熱い口づけでとける https://www.cmoa.jp/title/236751/\n",
            "純潔の罪 https://www.cmoa.jp/title/184272/\n",
            "今度は絶対に邪魔しませんっ! https://www.cmoa.jp/title/170828/\n",
            "BLゲームの主人公の弟であることに気がつきました https://www.cmoa.jp/title/234498/\n",
            "精霊魔法が使えない無能だと婚約破棄されたので、義妹の奴隷になるより追放を選びました https://www.cmoa.jp/title/267617/\n",
            "破滅の聖女は運命の夫の溺愛から逃れたい https://www.cmoa.jp/title/285946/\n",
            "名も知らず https://www.cmoa.jp/title/286269/\n",
            "推定悪役令嬢は国一番のブサイクに嫁がされるようです https://www.cmoa.jp/title/272284/\n",
            "悦覧禁止-暁月教授の怪異検証- https://www.cmoa.jp/title/284271/\n",
            "瓜を破る https://www.cmoa.jp/title/217954/\n",
            "結界師の一輪華 https://www.cmoa.jp/title/251291/\n",
            "甘いお菓子の後は甘い溺愛を～婚約破棄された令嬢は辺境伯子息に溺愛される～ https://www.cmoa.jp/title/286651/\n",
            "にぶんのいち夫婦 https://www.cmoa.jp/title/171657/\n",
            "悪女(と誤解される私)が腹黒王太子様の愛され妃になりそうです!? https://www.cmoa.jp/title/249073/\n",
            "木更津くんの××が見たい https://www.cmoa.jp/title/207107/\n",
            "未満。だけど愛して、愛して、愛しつくす https://www.cmoa.jp/title/262290/\n",
            "売られた辺境伯令嬢は隣国の王太子に溺愛される https://www.cmoa.jp/title/241514/\n",
            "------\n",
            "【少年マンガ】\n",
            "俺だけレベルアップな件 https://www.cmoa.jp/title/196532/\n",
            "葬送のフリーレン https://www.cmoa.jp/title/207742/\n",
            "とんでもスキルで異世界放浪メシ https://www.cmoa.jp/title/140801/\n",
            "ハイキュー！！ https://www.cmoa.jp/title/55867/\n",
            "新米オッサン冒険者、最強パーティに死ぬほど鍛えられて無敵になる。 https://www.cmoa.jp/title/201631/\n",
            "アラフォー男の異世界通販生活 https://www.cmoa.jp/title/185836/\n",
            "マッシュル-MASHLE- https://www.cmoa.jp/title/202198/\n",
            "生まれ変わった剣聖、剣士が冷遇される魔術至上主義の学園で無双する https://www.cmoa.jp/title/282713/\n",
            "僕は今すぐ前世の記憶を捨てたい。～憧れの田舎は人外魔境でした～@COMIC https://www.cmoa.jp/title/271770/\n",
            "赤羽骨子のボディガード https://www.cmoa.jp/title/259867/\n",
            "信じていた仲間達にダンジョン奥地で殺されかけたがギフト『無限ガチャ』でレベル9999の仲間達を手に入れて元パーティーメンバーと世界に復讐＆『ざまぁ！』します！ https://www.cmoa.jp/title/226740/\n",
            "奴隷を調教してハーレム作る https://www.cmoa.jp/title/279530/\n",
            "転生コロシアム ～最弱スキルで最強の女たちを攻略して奴隷ハーレム作ります～ https://www.cmoa.jp/title/259224/\n",
            "転生したらスライムだった件 https://www.cmoa.jp/title/104550/\n",
            "シャングリラ・フロンティア ～クソゲーハンター、神ゲーに挑まんとす～ https://www.cmoa.jp/title/209360/\n",
            "ひげを剃る。そして女子高生を拾う。 https://www.cmoa.jp/title/176023/\n",
            "望まぬ不死の冒険者 https://www.cmoa.jp/title/150041/\n",
            "酔っぱらい盗賊、奴隷の少女を買う https://www.cmoa.jp/title/262351/\n",
            "呪術廻戦 https://www.cmoa.jp/title/151961/\n",
            "ブルーロック https://www.cmoa.jp/title/160887/\n",
            "------\n",
            "【青年マンガ】\n",
            "キングダム https://www.cmoa.jp/title/37270/\n",
            "嘘とセフレ https://www.cmoa.jp/title/209001/\n",
            "嘆きの亡霊は引退したい ～最弱ハンターによる最強パーティ育成術～ https://www.cmoa.jp/title/186567/\n",
            "パンティーノート ～下着で交わる秘密ごと～ https://www.cmoa.jp/title/232117/\n",
            "再召喚された勇者は一般人として生きていく？ https://www.cmoa.jp/title/213768/\n",
            "薬屋のひとりごと～猫猫の後宮謎解き手帳～ https://www.cmoa.jp/title/142003/\n",
            "レッドムーダン～皇帝に成り上がった女～ https://www.cmoa.jp/title/275051/\n",
            "ダンジョン島で宿屋をやろう! 創造魔法を貰った俺の細腕繁盛記 https://www.cmoa.jp/title/224757/\n",
            "ここからが本番です～リベンジオフィスマッサージ～ https://www.cmoa.jp/title/279361/\n",
            "パラダイスヘル 分冊版\n",
            "パラダイスヘル https://www.cmoa.jp/title/266867/\n",
            "レンタル・マーダー～復讐のプロ、お貸しします～ https://www.cmoa.jp/title/261008/\n",
            "ダンジョン飯 https://www.cmoa.jp/title/90570/\n",
            "九条の大罪 https://www.cmoa.jp/title/216805/\n",
            "親友の秘密 https://www.cmoa.jp/title/231319/\n",
            "ゴールデンカムイ https://www.cmoa.jp/title/89452/\n",
            "魔王様、リトライ！R https://www.cmoa.jp/title/202946/\n",
            "異形頭さんとニンゲンちゃん https://www.cmoa.jp/title/273584/\n",
            "ガチャを回して仲間を増やす 最強の美少女軍団を作り上げろ THE COMIC https://www.cmoa.jp/title/161321/\n",
            "悪魔だった君たちへ https://www.cmoa.jp/title/199227/\n",
            "無職転生 ～異世界行ったら本気だす～ https://www.cmoa.jp/title/87651/\n",
            "------\n",
            "【BLコミック】\n",
            "后宮のオメガ https://www.cmoa.jp/title/279441/\n",
            "相愛系小説家とのロマンスについて https://www.cmoa.jp/title/287390/\n",
            "獣の王と狼面の番 https://www.cmoa.jp/title/273240/\n",
            "離れられない、逃がしてやれない https://www.cmoa.jp/title/287553/\n",
            "好きすぎるから早く抱け https://www.cmoa.jp/title/287379/\n",
            "翻弄系小説家とのロマンスについて https://www.cmoa.jp/title/251122/\n",
            "ふたりあそび https://www.cmoa.jp/title/253799/\n",
            "The Red Thread https://www.cmoa.jp/title/236459/\n",
            "ギヴン https://www.cmoa.jp/title/92972/\n",
            "ドアの向こうにはロマンス https://www.cmoa.jp/title/287021/\n",
            "パーフェクトアディクション https://www.cmoa.jp/title/262120/\n",
            "ないしょのストーカーさん https://www.cmoa.jp/title/279452/\n",
            "噛み痕から、初恋 https://www.cmoa.jp/title/286996/\n",
            "高嶺の花は、乱されたい https://www.cmoa.jp/title/240855/\n",
            "誰か夢だと言ってくれ https://www.cmoa.jp/title/228949/\n",
            "獣の王と狼面の番―続― https://www.cmoa.jp/title/288678/\n",
            "宵闇シュガーキャット https://www.cmoa.jp/title/276136/\n",
            "Kiss me crying https://www.cmoa.jp/title/286995/\n",
            "鬼上司・獄寺さんは暴かれたい。 https://www.cmoa.jp/title/213527/\n",
            "夜画帳 https://www.cmoa.jp/title/214632/\n",
            "------\n",
            "【TLコミック】\n",
            "絶倫幼なじみの溺愛Hで満たされたい https://www.cmoa.jp/title/282418/\n",
            "おくちがエッチな弱点だって、ライバルのエリート同僚にバレてしまいました https://www.cmoa.jp/title/229100/\n",
            "愛が重い騎士公爵は、追放令嬢のすべてを奪い尽くしたい。 https://www.cmoa.jp/title/254800/\n",
            "制服の恋情 身代わり結婚ノスタルジア https://www.cmoa.jp/title/281083/\n",
            "奈々子と薫 堕落していく、僕たちは。 https://www.cmoa.jp/title/243475/\n",
            "僕しか知らない君のナカ。 https://www.cmoa.jp/title/128625/\n",
            "キスでふさいで、バレないで。 https://www.cmoa.jp/title/203997/\n",
            "転生先でメタ発言をしたら攻略対象の王子が豹変しました https://www.cmoa.jp/title/287477/\n",
            "SEX DRIVE https://www.cmoa.jp/title/223146/\n",
            "いじわる幼馴染ととろあま夫婦生活 ～この契約婚は、計画的溺愛でした～ https://www.cmoa.jp/title/270007/\n",
            "命に替えても守ると誓った～クールな護衛騎士は召喚された聖女を熱く溺愛する～ https://www.cmoa.jp/title/273001/\n",
            "九条さんは一晩中抱けるド絶倫～豹変男子のイキすぎ絶頂テクニック https://www.cmoa.jp/title/229220/\n",
            "こんなことヤリたいの!～誰にも止められない彼女～ https://www.cmoa.jp/title/278332/\n",
            "午前0時、とけあう熱～カラダが覚えてる運命のシンデレラ https://www.cmoa.jp/title/275308/\n",
            "幼なじみバーテンダーと始める快感レッスン https://www.cmoa.jp/title/211288/\n",
            "絶頂相手は婚約者!?～今夜もイクまでハメ落ちる https://www.cmoa.jp/title/265098/\n",
            "じらし上手な久堂部長は、今夜も愛妻をグズグズに抱きほぐす。 https://www.cmoa.jp/title/263121/\n",
            "年下メダリストは一途な獣 ～身長差40センチ、私たちの愛の育み方～ https://www.cmoa.jp/title/231730/\n",
            "かわいい親友は、時々オトコ。 https://www.cmoa.jp/title/246969/\n",
            "セックス革命起こしませんか？ ～謎の独身貴族に彼氏宣言されました～ https://www.cmoa.jp/title/214179/\n",
            "------\n",
            "【シーモア先行】\n",
            "秘密の授業 https://www.cmoa.jp/title/215480/\n",
            "ICE LOVE：アイス・ラブ https://www.cmoa.jp/title/275425/\n",
            "noicomi鬼の花嫁 https://www.cmoa.jp/title/239726/\n",
            "親友の彼氏 https://www.cmoa.jp/title/284883/\n",
            "------\n",
            "【オリジナル】\n",
            "東郷家へ嫁いだ話 https://www.cmoa.jp/title/263631/\n",
            "妖狐の旦那さま～大正花嫁奇譚～ https://www.cmoa.jp/title/247499/\n",
            "やり直し新卒は今度こそキミを救いたい!? https://www.cmoa.jp/title/265330/\n",
            "十億のアレ。～吉原いちの花魁～ https://www.cmoa.jp/title/156997/\n",
            "二段ベッド https://www.cmoa.jp/title/259794/\n",
            "宮路夫婦は恋愛できない https://www.cmoa.jp/title/252923/\n",
            "能なし巫女は、鬼神さまに愛される https://www.cmoa.jp/title/245010/\n",
            "彼は『これ』は復讐ではない、と言った https://www.cmoa.jp/title/257777/\n",
            "0から始めるオフィスラブ https://www.cmoa.jp/title/194399/\n",
            "ヤりまくりアプリ https://www.cmoa.jp/title/250587/\n",
            "椎名さん、沼ってます。 https://www.cmoa.jp/title/242964/\n",
            "恋という毒を飲むことにした https://www.cmoa.jp/title/271092/\n",
            "------\n",
            "【オトナコミック】\n",
            "絶頂リフレ 駅前の性感マッサージ店で◯◯になっちゃう女の子の話 https://www.cmoa.jp/title/286055/\n",
            "もうイッてるから腰とめてぇ…!ラブドール（※本人）にぶつける本気ピストン https://www.cmoa.jp/title/227961/\n",
            "入り浸りJKにアソコ使わせてもらう話 https://www.cmoa.jp/title/265345/\n",
            "パパの寝室は娘友達のたまり場 https://www.cmoa.jp/title/242363/\n",
            "お姉さんとシよ？～えちんぽカードでやりたい放題～ https://www.cmoa.jp/title/272516/\n",
            "アプリでマッチングした相手は、堅物な担任女教師でした。 https://www.cmoa.jp/title/231249/\n",
            "陰キャΩの私がヤンキーαの彼と番になりました https://www.cmoa.jp/title/287380/\n",
            "眠るあの子にハメてみた。～入れてもイっても起きないんだもんっ！ https://www.cmoa.jp/title/124203/\n",
            "生イキJKに中●し調教～めちゃくちゃに突いて、奥の方に出してあげるね https://www.cmoa.jp/title/193094/\n",
            "「あと3回はイケるよね?」夫の帰宅前、絶倫義弟に何度もハメ倒される妻 https://www.cmoa.jp/title/218011/\n",
            "僕の方が先に好きだった子が後輩のチャラ男に中出しされまくる7日間 https://www.cmoa.jp/title/250656/\n",
            "カラミざかり https://www.cmoa.jp/title/162176/\n",
            "ぼくたちはお姉ちゃんの虜 https://www.cmoa.jp/title/259604/\n",
            "そういうコンセプト https://www.cmoa.jp/title/286906/\n",
            "僕の母さんで、僕の好きな人。 https://www.cmoa.jp/title/232024/\n",
            "せんせいと、わたしと。～あなたのことをしりたくて～ https://www.cmoa.jp/title/231511/\n",
            "恋のむきだし https://www.cmoa.jp/title/285104/\n",
            "片端の桜 https://www.cmoa.jp/title/265998/\n",
            "贄の花嫁は今宵も獣と契りを交わす https://www.cmoa.jp/title/277558/\n",
            "奥さん、全裸で土下座しろよ～隣人DQNのイボイボチ●ポで突かれた人妻は…～ https://www.cmoa.jp/title/215341/\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'spreadsheetId': '1RiLchx4pkQ_vdngW3UIG49xuhoZEThM4rAhuTPJQdH4',\n",
              " 'tableRange': \"'スクレイピング結果'!A1:C21\",\n",
              " 'updates': {'spreadsheetId': '1RiLchx4pkQ_vdngW3UIG49xuhoZEThM4rAhuTPJQdH4',\n",
              "  'updatedRange': \"'スクレイピング結果'!A22:C156\",\n",
              "  'updatedRows': 135,\n",
              "  'updatedColumns': 3,\n",
              "  'updatedCells': 405}}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### コミックシーモア発売予定作品\n",
        "---\n"
      ],
      "metadata": {
        "id": "XkPAYr2742oD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "cmoa_schedule_data_to_insert = []\n",
        "# スクレイピング対象の URL にリクエストを送り HTML を取得する\n",
        "res = requests.get('https://www.cmoa.jp/newrelease/schedule/boy/')\n",
        "\n",
        "def get_release_books(number):\n",
        "  soup = BeautifulSoup(res.content, 'html.parser', from_encoding='utf-8')\n",
        "  title = soup.select_one(f'#home > section.co_container.pc_with > div > div > section.newrelease_area > div:nth-of-type({number}) > div')\n",
        "  try:\n",
        "    text_content = title.text.strip()\n",
        "    match = re.search(r\"\\((\\d+)\\)\", text_content)\n",
        "\n",
        "    # 抽出結果を取得\n",
        "    if match:\n",
        "        # 正規表現で括弧内の数字を抽出\n",
        "        count = int(match.group(1))\n",
        "\n",
        "    print(\"------\")\n",
        "    print(\"【\"+text_content+ \"】\")\n",
        "\n",
        "    for k in range(count+1):\n",
        "      elems = soup.select(f'#home > section.co_container.pc_with > div > div > section.newrelease_area > div:nth-of-type({number}) > ul > li:nth-of-type({k +1}) > div > a')\n",
        "      role = soup.select_one(f'#home > section.co_container.pc_with > div > div > section.newrelease_area > div:nth-of-type({number}) > ul > li:nth-of-type({k +1}) > div > div.vol_num')\n",
        "      if role != None:\n",
        "        role_text = role.text\n",
        "        if role_text == \"1巻\" or role_text.startswith(\"1-\"):\n",
        "          if elems:\n",
        "            link = elems[0]['href']\n",
        "            full_path = \"https://www.cmoa.jp\" + link\n",
        "            text = elems[0].text.strip()\n",
        "            if text:\n",
        "                text = check_duplicate(text)\n",
        "                text = delete_unnecessary_words(text)\n",
        "                if text[:5] in [item[:5] for item in duplication_set] and text[-3:] in [item[-3:] for item in duplication_set]:\n",
        "                  continue\n",
        "                print(text, full_path)\n",
        "                cmoa_schedule_data_to_insert.append([text, full_path, \"コミックシーモア発売予定\" + \"【\"+ text_content + \"】\"])\n",
        "                duplication_set.add(text)\n",
        "\n",
        "  except AttributeError:\n",
        "    print(\"Error: 'title' is NoneType. Exiting the program.\")\n",
        "    exit()\n",
        "\n",
        "# tommorrow\n",
        "get_release_books(1)\n",
        "\n",
        "# the day after tomorrow ..\n",
        "get_release_books(2)\n",
        "get_release_books(3)\n",
        "\n",
        "st.append_rows(values=cmoa_schedule_data_to_insert)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgzkat7y7VW-",
        "outputId": "fb00f56c-154a-4131-980e-1c24bc166e3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------\n",
            "【3/5(火)発売予定作品 (22)】\n",
            "------\n",
            "【3/6(水)発売予定作品 (58)】\n",
            "------\n",
            "【3/7(木)発売予定作品 (39)】\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'spreadsheetId': '1RiLchx4pkQ_vdngW3UIG49xuhoZEThM4rAhuTPJQdH4',\n",
              " 'tableRange': \"'スクレイピング結果'!A1:C168\",\n",
              " 'updates': {'spreadsheetId': '1RiLchx4pkQ_vdngW3UIG49xuhoZEThM4rAhuTPJQdH4',\n",
              "  'updatedRange': \"'スクレイピング結果'!A169\"}}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Renta! 1位～5位取得\n",
        "---\n"
      ],
      "metadata": {
        "id": "dgxuBapbS1vz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google_colab_selenium as gs\n",
        "import re\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.common.by import By\n",
        "\n",
        "\n",
        "options = Options()\n",
        "options.add_argument(\"--headless\")\n",
        "\n",
        "get_list = [\"少女漫画\",\"少年漫画\",\"青年漫画\",\"映像化作品\",\"ボーイズラブ漫画\",\"ティーンズラブコミック\",\"レディースコミック\",\"ヤングレディース\",\"美女・美少女\",\"ルポ・エッセイ\",\"タテコミ\"]\n",
        "renta_ranking_data_to_insert = []\n",
        "\n",
        "print(\"connectiong to remote browser...\")\n",
        "driver = gs.Chrome(options=options)\n",
        "\n",
        "driver.get(\"https://renta.papy.co.jp/renta/sc/frm/page/ranking_c.htm?type=week\")\n",
        "\n",
        "rankign_item_wrap_list = driver.find_elements(\n",
        "    By.XPATH, '//div[@id=\"ranking_item\"]/div[@class=\"itemRank_wrap\"]/h2/span'\n",
        ")\n",
        "for ranking_item_wrap in rankign_item_wrap_list:\n",
        "    if ranking_item_wrap.text not in get_list:\n",
        "      continue\n",
        "    print(\"------\")\n",
        "    print(f\"【{ranking_item_wrap.text}】\")\n",
        "    item_contents_list = driver.find_elements(\n",
        "        By.XPATH,\n",
        "        f'//div[@id=\"ranking_item\"]/div[@id=\"{ranking_item_wrap.text}\"]/div[@class=\"contentsRank_wrap\"]/div[@class=\"itemContents\"]',\n",
        "    )\n",
        "    count = 0\n",
        "    for item_contents in item_contents_list:\n",
        "        manga_title = item_contents.find_element(\n",
        "            By.XPATH,\n",
        "            \"./a/p\",\n",
        "        ).text\n",
        "        manga_url = item_contents.find_element(\n",
        "            By.XPATH,\n",
        "            \"./a\",\n",
        "        ).get_attribute(\"href\")\n",
        "        # 最初と最後の数文字で検出するように変更\n",
        "        manga_title = check_duplicate(manga_title)\n",
        "        manga_title = delete_unnecessary_words(manga_title)\n",
        "        if manga_title[:5] in [item[:5] for item in duplication_set] and manga_title[-3:] in [item[-3:] for item in duplication_set]:\n",
        "          continue\n",
        "        print(f\"{manga_title} {manga_url}\")\n",
        "        renta_ranking_data_to_insert.append([manga_title, manga_url, \"renta上位\" + \"【\"+ ranking_item_wrap.text + \"】\"])\n",
        "        duplication_set.add(manga_title)\n",
        "        count += 1\n",
        "        if count == 5:\n",
        "          break\n",
        "\n",
        "st.append_rows(values=renta_ranking_data_to_insert)\n",
        "driver.quit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "id": "N1TZQ0F0S-6F",
        "outputId": "f4a8710e-e6c5-4269-e0b7-abb7d8fad53e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "connectiong to remote browser...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <div class=\"spinner-container\">\n",
              "                <div class=\"spinner\" id=\"b5ffb007-bc64-4f04-ba0b-f1a344de2700-circle\"></div>\n",
              "                <div class=\"spinner-text\" id=\"b5ffb007-bc64-4f04-ba0b-f1a344de2700-text\">Initializing Chromedriver</div>\n",
              "            </div>\n",
              "            <style>\n",
              "                @keyframes spin {\n",
              "                    from { transform: rotate(0deg); }\n",
              "                    to { transform: rotate(360deg); }\n",
              "                }\n",
              "\n",
              "                .spinner-container {\n",
              "                    display: flex;\n",
              "                    align-items: center;\n",
              "                    margin-bottom: 3px;\n",
              "                }\n",
              "\n",
              "                .spinner {\n",
              "                    border: 3px solid rgba(0, 0, 0, 0.1);\n",
              "                    border-left-color: lightblue;\n",
              "                    border-radius: 50%;\n",
              "                    width: 12px;\n",
              "                    height: 12px;\n",
              "                    animation: spin 1s linear infinite;\n",
              "                }\n",
              "\n",
              "                .spinner-text {\n",
              "                    padding-left: 6px;\n",
              "                }\n",
              "            </style>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            const element = document.getElementById(\"b5ffb007-bc64-4f04-ba0b-f1a344de2700-circle\");\n",
              "            element.style.border = \"3px solid limegreen\";\n",
              "            element.style.animation = \"none\";\n",
              "\n",
              "            const text = document.getElementById(\"b5ffb007-bc64-4f04-ba0b-f1a344de2700-text\");\n",
              "            text.innerText = \"Initialized Chromedriver\";\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------\n",
            "【少女漫画】\n",
            "------\n",
            "【少年漫画】\n",
            "------\n",
            "【青年漫画】\n",
            "------\n",
            "【映像化作品】\n",
            "------\n",
            "【ボーイズラブ漫画】\n",
            "------\n",
            "【ティーンズラブコミック】\n",
            "成瀬くんは溺愛オオカミ―理想の彼氏は幼なじみでした― https://renta.papy.co.jp/renta/sc/frm/item/164095/title/892901/\n",
            "------\n",
            "【レディースコミック】\n",
            "------\n",
            "【ヤングレディース】\n",
            "サレ妻の復讐～魔性の刺青～ https://renta.papy.co.jp/renta/sc/frm/item/226756/title/2492400/\n",
            "ビジネス婚─好きになったら離婚します─ https://renta.papy.co.jp/renta/sc/frm/item/342699/title/2435722/\n",
            "------\n",
            "【美女・美少女】\n",
            "レス妻が性感エステで「また…イク…っ」～うねる指で奥までほぐされ… https://renta.papy.co.jp/renta/sc/frm/item/188855/title/2516380/\n",
            "幼馴染にイかされるなんて…！同居初日に喧嘩エッチ https://renta.papy.co.jp/renta/sc/frm/item/143887/title/2522457/\n",
            "家族だけど大丈夫 https://renta.papy.co.jp/renta/sc/frm/item/311723/title/2522441/\n",
            "------\n",
            "【タテコミ】\n",
            "奉公物語～僕のお嬢様～ https://renta.papy.co.jp/renta/sc/frm/item/342470/title/2509889/\n",
            "旦那の浮気相手とLINE友達になってみた https://renta.papy.co.jp/renta/sc/frm/item/337767/title/2397031/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Renta!独占\n",
        "---\n"
      ],
      "metadata": {
        "id": "3pkGZDV1op9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google_colab_selenium as gs\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.common.by import By\n",
        "\n",
        "options = Options()\n",
        "options.add_argument(\"--headless\")\n",
        "\n",
        "print(\"connectiong to remote browser...\")\n",
        "driver = gs.Chrome(options=options)\n",
        "\n",
        "driver.get(\"https://renta.papy.co.jp/renta/sc/frm/page/original/c_comicspia.htm\")\n",
        "\n",
        "renta_original_data_to_insert = []\n",
        "\n",
        "def get_renta_comicspia(number):\n",
        "  topics_wrap_list = driver.find_elements(\n",
        "      By.XPATH, f'//*[@id=\"comicspia\"]/div[{number+1}]'\n",
        "  )\n",
        "  # topics_contents_innerwrapの個数をカウントする\n",
        "  for topics_wrap in topics_wrap_list:\n",
        "      inner_wrap_list = topics_wrap.find_elements(By.CLASS_NAME, 'topics_contents_innerwrap')\n",
        "      count_inner_wrap_list = len(inner_wrap_list)\n",
        "      # print(\"inner_wrap の個数:\", len(inner_wrap_list))\n",
        "\n",
        "  title_list = driver.find_elements(\n",
        "      By.XPATH, '//*[@id=\"newContents\"]/span'\n",
        "  )\n",
        "  for title in title_list:\n",
        "    print(\"------\")\n",
        "    print(\"【\" + title.text + \"】\")\n",
        "\n",
        "  # topics_contents_innerwrapの中身取得\n",
        "  for i in range(1,count_inner_wrap_list+1):\n",
        "    book_title_list = driver.find_elements(\n",
        "      By.XPATH, f'//*[@id=\"comicspia\"]/div[{number+1}]/div[{i}]/div/div[1]/div/div[1]/span[2]'\n",
        "  )\n",
        "    for book in book_title_list:\n",
        "      book_title = book.text\n",
        "\n",
        "    book_link_list = driver.find_elements(\n",
        "      By.XPATH, f'//*[@id=\"comicspia\"]/div[{number+1}]/div[{i}]/div/div[1]/a'\n",
        "  )\n",
        "    for link in book_link_list:\n",
        "      book_link = link.get_attribute(\"href\")\n",
        "    book_title = check_duplicate(book_title)\n",
        "    book_title = delete_unnecessary_words(book_title)\n",
        "    if book_title[:5] in [item[:5] for item in duplication_set] and book_title[-3:] in [item[-3:] for item in duplication_set]:\n",
        "      continue\n",
        "    print(book_title, book_link)\n",
        "    renta_original_data_to_insert.append([book_title, book_link, \"renta独占\"])\n",
        "    duplication_set.add(book_title)\n",
        "\n",
        "def get_renta_comicspia2(number):\n",
        "  # topics_wrap_list = driver.find_elements(\n",
        "  #     By.XPATH, f'//*[@id=\"comicspia\"]/div[{number+1}]'\n",
        "  # )\n",
        "  # # topics_contents_innerwrapの個数をカウントする\n",
        "  # for topics_wrap in topics_wrap_list:\n",
        "  #     inner_wrap_list = topics_wrap.find_elements(By.CLASS_NAME, 'topics_contents_innerwrap')\n",
        "  #     count_inner_wrap_list = len(inner_wrap_list)\n",
        "  #     # print(\"inner_wrap の個数:\", len(inner_wrap_list))\n",
        "\n",
        "  # title_list = driver.find_elements(\n",
        "  #     By.XPATH, '//*[@id=\"saleContents\"]/span'\n",
        "  # )\n",
        "  # for title in title_list:\n",
        "  #   print(\"------\")\n",
        "  #   print(\"【\" + title.text + \"】\")\n",
        "\n",
        "  # topics_contents_innerwrapの中身取得\n",
        "  # for i in range(1,count_inner_wrap_list):\n",
        "  #   book_title_list = driver.find_elements(\n",
        "  #     By.XPATH, f'//*[@id=\"comicspia\"]/div[{number+1}]/div[{i}]/div/div[1]/div/div[2]'\n",
        "  # )\n",
        "  #   for book in book_title_list:\n",
        "  #     book_title = book.text\n",
        "\n",
        "  #   book_link_list = driver.find_elements(\n",
        "  #     By.XPATH, f'//*[@id=\"comicspia\"]/div[{number+1}]/div[{i}]/div/div[1]/a'\n",
        "  # )\n",
        "  #   for link in book_link_list:\n",
        "  #     book_link = link.get_attribute(\"href\")\n",
        "  #   book_title = check_duplicate(book_title)\n",
        "  #   if book_title[:5] in [item[:5] for item in duplication_set] and book_title[-3:] in [item[-3:] for item in duplication_set]:\n",
        "  #     continue\n",
        "  #   print(book_title, book_link)\n",
        "  #   renta_original_data_to_insert.append([book_title, book_link, \"renta独占\"])\n",
        "  #   duplication_set.add(book_title)\n",
        "\n",
        "  # 最下部取得\n",
        "  title_list = driver.find_elements(\n",
        "      By.XPATH, f'//*[@id=\"comicspia\"]/div[{number+1}]/h3/span[1]'\n",
        "  )\n",
        "  for title in title_list:\n",
        "    print(\"------\")\n",
        "    print(\"【\" + title.text + \"】\")\n",
        "\n",
        "  # contents_list = driver.find_elements(\n",
        "  #     By.XPATH, f'//*[@id=\"comicspia\"]/div[{number+1}]/div[4]/ul'\n",
        "  # )\n",
        "  contents_list = driver.find_elements(\n",
        "      By.XPATH, f'//*[@id=\"comicspia\"]/div[{number+1}]/div/ul'\n",
        "  )\n",
        "\n",
        "  # contents_listの個数をカウントする\n",
        "  for content in contents_list:\n",
        "      contents_li = content.find_elements(By.CLASS_NAME, 'contents_list')\n",
        "      count_contents_li = len(contents_li)\n",
        "\n",
        "  for li_content in range(1, count_contents_li+1):\n",
        "    book_title_list = driver.find_elements(\n",
        "      By.XPATH, f'//*[@id=\"comicspia\"]/div[{number+1}]/div/ul/li[{li_content}]/a[1]/div[2]'\n",
        "  )\n",
        "    for book in book_title_list:\n",
        "      book_title = book.text\n",
        "\n",
        "    book_link_list = driver.find_elements(\n",
        "      By.XPATH, f'//*[@id=\"comicspia\"]/div[{number+1}]/div/ul/li[{li_content}]/a[1]'\n",
        "  )\n",
        "    for link in book_link_list:\n",
        "      book_link = link.get_attribute(\"href\")\n",
        "    book_title = check_duplicate(book_title)\n",
        "    book_title = delete_unnecessary_words(book_title)\n",
        "    if book_title[:5] in [item[:5] for item in duplication_set] and book_title[-3:] in [item[-3:] for item in duplication_set]:\n",
        "      continue\n",
        "    print(book_title, book_link)\n",
        "    renta_original_data_to_insert.append([book_title, book_link, \"renta独占\"])\n",
        "    duplication_set.add(book_title)\n",
        "\n",
        "def get_renta_comicspia3(number):\n",
        "  topics_wrap_list = driver.find_elements(\n",
        "      By.XPATH, f'//*[@id=\"comicspia\"]/div[{number+1}]'\n",
        "  )\n",
        "  # topics_contents_innerwrapの個数をカウントする\n",
        "  for topics_wrap in topics_wrap_list:\n",
        "      inner_wrap_list = topics_wrap.find_elements(By.CLASS_NAME, 'topics_contents_innerwrap')\n",
        "      count_inner_wrap_list = len(inner_wrap_list)\n",
        "      # print(\"inner_wrap の個数:\", len(inner_wrap_list))\n",
        "\n",
        "  title_list = driver.find_elements(\n",
        "      By.XPATH, '//*[@id=\"listContents\"]/span'\n",
        "  )\n",
        "  for title in title_list:\n",
        "    print(\"------\")\n",
        "    print(\"【\" + title.text + \"】\")\n",
        "\n",
        "  # topics_contents_innerwrapの中身取得\n",
        "  for i in range(1,count_inner_wrap_list):\n",
        "    book_title_list = driver.find_elements(\n",
        "      By.XPATH, f'//*[@id=\"comicspia\"]/div[{number+1}]/div[{i}]/div/div[1]/div/div[1]'\n",
        "  )\n",
        "    for book in book_title_list:\n",
        "      book_title = book.text\n",
        "\n",
        "    book_link_list = driver.find_elements(\n",
        "      By.XPATH, f'//*[@id=\"comicspia\"]/div[{number+1}]/div[{i}]/div/div[1]/a'\n",
        "  )\n",
        "    for link in book_link_list:\n",
        "      book_link = link.get_attribute(\"href\")\n",
        "    book_title = check_duplicate(book_title)\n",
        "    book_title = delete_unnecessary_words(book_title)\n",
        "    if book_title[:5] in [item[:5] for item in duplication_set] and book_title[-3:] in [item[-3:] for item in duplication_set]:\n",
        "      continue\n",
        "    print(book_title, book_link)\n",
        "    renta_original_data_to_insert.append([book_title, book_link, \"renta独占\"])\n",
        "    duplication_set.add(book_title)\n",
        "\n",
        "  # 最下部取得\n",
        "  contents_list = driver.find_elements(\n",
        "      By.XPATH, f'//*[@id=\"comicspia\"]/div[{number+1}]/div[2]/ul'\n",
        "  )\n",
        "\n",
        "  # contents_listの個数をカウントする\n",
        "  for content in contents_list:\n",
        "      contents_li = content.find_elements(By.CLASS_NAME, 'contents_list')\n",
        "      count_contents_li = len(contents_li)\n",
        "\n",
        "  for li_content in range(1, count_contents_li+1):\n",
        "    book_title_list = driver.find_elements(\n",
        "      By.XPATH, f'//*[@id=\"comicspia\"]/div[{number+1}]/div[2]/ul/li[{li_content}]/a[1]/div[2]'\n",
        "  )\n",
        "    for book in book_title_list:\n",
        "      book_title = book.text\n",
        "\n",
        "    book_link_list = driver.find_elements(\n",
        "      By.XPATH, f'//*[@id=\"comicspia\"]/div[{number+1}]/div[2]/ul/li[{li_content}]/a[1]'\n",
        "  )\n",
        "    for link in book_link_list:\n",
        "      book_link = link.get_attribute(\"href\")\n",
        "    book_title = check_duplicate(book_title)\n",
        "    book_title = delete_unnecessary_words(book_title)\n",
        "    if book_title[:5] in [item[:5] for item in duplication_set] and book_title[-3:] in [item[-3:] for item in duplication_set]:\n",
        "      continue\n",
        "    print(book_title, book_link)\n",
        "    renta_original_data_to_insert.append([book_title, book_link, \"renta独占\"])\n",
        "    duplication_set.add(book_title)\n",
        "\n",
        "def get_renta_comicspia4(number, title):\n",
        "  title_list = driver.find_elements(\n",
        "      By.XPATH, f'//*[@id=\"{title}\"]/span'\n",
        "  )\n",
        "  for title in title_list:\n",
        "    print(\"------\")\n",
        "    print(\"【\" + title.text + \"】\")\n",
        "\n",
        "  # 最下部取得\n",
        "  contents_list = driver.find_elements(\n",
        "      By.XPATH, f'//*[@id=\"comicspia\"]/div[{number+1}]/div/ul'\n",
        "  )\n",
        "\n",
        "  # contents_listの個数をカウントする\n",
        "  for content in contents_list:\n",
        "      contents_li = content.find_elements(By.CLASS_NAME, 'contents_list')\n",
        "      count_contents_li = len(contents_li)\n",
        "\n",
        "  for li_content in range(1, count_contents_li+1):\n",
        "    book_title_list = driver.find_elements(\n",
        "      By.XPATH, f'//*[@id=\"comicspia\"]/div[{number+1}]/div/ul/li[{li_content}]/a[1]/div[2]'\n",
        "  )\n",
        "    for book in book_title_list:\n",
        "      book_title = book.text\n",
        "\n",
        "    book_link_list = driver.find_elements(\n",
        "      By.XPATH, f'//*[@id=\"comicspia\"]/div[{number+1}]/div/ul/li[{li_content}]/a[1]'\n",
        "  )\n",
        "    for link in book_link_list:\n",
        "      book_link = link.get_attribute(\"href\")\n",
        "    book_title = check_duplicate(book_title)\n",
        "    book_title = delete_unnecessary_words(book_title)\n",
        "    if book_title[:5] in [item[:5] for item in duplication_set] and book_title[-3:] in [item[-3:] for item in duplication_set]:\n",
        "      continue\n",
        "    print(book_title, book_link)\n",
        "    renta_original_data_to_insert.append([book_title, book_link, \"renta独占\"])\n",
        "    duplication_set.add(book_title)\n",
        "\n",
        "\n",
        "get_renta_comicspia(1)\n",
        "get_renta_comicspia2(2)\n",
        "get_renta_comicspia3(3)\n",
        "get_renta_comicspia4(4,\"specialContents\")\n",
        "get_renta_comicspia4(5,\"tatecomi\")\n",
        "get_renta_comicspia4(6,\"enovel\")\n",
        "\n",
        "st.append_rows(values=renta_original_data_to_insert)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "id": "C58gvykIw8-f",
        "outputId": "a3ec0560-d953-4515-bde3-b4a562cd6490"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "connectiong to remote browser...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <div class=\"spinner-container\">\n",
              "                <div class=\"spinner\" id=\"e080fd46-4213-473f-bf35-71dd9fc6d8c6-circle\"></div>\n",
              "                <div class=\"spinner-text\" id=\"e080fd46-4213-473f-bf35-71dd9fc6d8c6-text\">Initializing Chromedriver</div>\n",
              "            </div>\n",
              "            <style>\n",
              "                @keyframes spin {\n",
              "                    from { transform: rotate(0deg); }\n",
              "                    to { transform: rotate(360deg); }\n",
              "                }\n",
              "\n",
              "                .spinner-container {\n",
              "                    display: flex;\n",
              "                    align-items: center;\n",
              "                    margin-bottom: 3px;\n",
              "                }\n",
              "\n",
              "                .spinner {\n",
              "                    border: 3px solid rgba(0, 0, 0, 0.1);\n",
              "                    border-left-color: lightblue;\n",
              "                    border-radius: 50%;\n",
              "                    width: 12px;\n",
              "                    height: 12px;\n",
              "                    animation: spin 1s linear infinite;\n",
              "                }\n",
              "\n",
              "                .spinner-text {\n",
              "                    padding-left: 6px;\n",
              "                }\n",
              "            </style>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            const element = document.getElementById(\"e080fd46-4213-473f-bf35-71dd9fc6d8c6-circle\");\n",
              "            element.style.border = \"3px solid limegreen\";\n",
              "            element.style.animation = \"none\";\n",
              "\n",
              "            const text = document.getElementById(\"e080fd46-4213-473f-bf35-71dd9fc6d8c6-text\");\n",
              "            text.innerText = \"Initialized Chromedriver\";\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------\n",
            "【新刊をチェック！】\n",
            "------\n",
            "【期間限定で対象作品が無料！】\n",
            "------\n",
            "【COMICスピア作品一覧】\n",
            "------\n",
            "【特装版でまとめて読む！】\n",
            "------\n",
            "【アニコミも好評配信中！】\n",
            "------\n",
            "【オススメ特集！】\n",
            "------\n",
            "【タテコミ作品】\n",
            "------\n",
            "【絵ノベル版も要チェック！】\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'spreadsheetId': '1RiLchx4pkQ_vdngW3UIG49xuhoZEThM4rAhuTPJQdH4',\n",
              " 'tableRange': \"'シート65'!A1:C558\",\n",
              " 'updates': {'spreadsheetId': '1RiLchx4pkQ_vdngW3UIG49xuhoZEThM4rAhuTPJQdH4',\n",
              "  'updatedRange': \"'シート65'!A559\"}}"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### booklive オリジナル独占\n",
        "---"
      ],
      "metadata": {
        "id": "TkFlGg4LrOcN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "get_dict = {\"すべて\": \"\", \"少年・青年マンガ\": \"/comic\", \"少女・女性マンガ\": \"/comicf\", \"TL\": \"/teenslove\", \"BL\": \"/boyslove\"}\n",
        "booklive_data_to_insert = []\n",
        "\n",
        "def get_booklive_comics(soup, title):\n",
        "    roop_booklive(soup, 1, title)\n",
        "    roop_booklive(soup, 2, title)\n",
        "\n",
        "def roop_booklive(soup, number, title):\n",
        "    for k in range(5):\n",
        "        elems = soup.select(f'#area_new > div.area_inner > div:nth-of-type({number}) > div:nth-of-type({k+1}) > div.txtarea > div > a')\n",
        "        if elems:\n",
        "            link = elems[0]['href']\n",
        "            full_path = \"https://booklive.jp\" + link\n",
        "\n",
        "            res2 = requests.get(full_path)\n",
        "            soup2 = BeautifulSoup(res2.text, 'html.parser')\n",
        "            elems2 = soup2.select('#product_display_1')\n",
        "            text = elems2[0].text.strip()\n",
        "            text = check_duplicate(text)\n",
        "            text = delete_unnecessary_words(text)\n",
        "            if text[:5] in [item[:5] for item in duplication_set] and text[-3:] in [item[-3:] for item in duplication_set]:\n",
        "              continue\n",
        "            print(text, full_path)\n",
        "            booklive_data_to_insert.append([text, full_path, \"bookliveオリジナル独占\"+ \"【\"+ title + \"】\"])\n",
        "            duplication_set.add(text)\n",
        "\n",
        "for k, v in get_dict.items():\n",
        "    res = requests.get('https://booklive.jp/original-comic' + v)\n",
        "    soup = BeautifulSoup(res.text, 'html.parser')\n",
        "    kind_of_elems = soup.select('#area_new > div.heading_title.add_pickup_link > h2')\n",
        "    print(\"------\")\n",
        "    print(\"【\" + k + \"】\")\n",
        "    get_booklive_comics(soup, k)\n",
        "\n",
        "st.append_rows(values=booklive_data_to_insert)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iktXeTArTbA",
        "outputId": "cba93be6-5f12-49f6-964c-e8417933e267"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------\n",
            "【すべて】\n",
            "------\n",
            "【少年・青年マンガ】\n",
            "------\n",
            "【少女・女性マンガ】\n",
            "------\n",
            "【TL】\n",
            "------\n",
            "【BL】\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'spreadsheetId': '1RiLchx4pkQ_vdngW3UIG49xuhoZEThM4rAhuTPJQdH4',\n",
              " 'tableRange': \"'シート65'!A1:C558\",\n",
              " 'updates': {'spreadsheetId': '1RiLchx4pkQ_vdngW3UIG49xuhoZEThM4rAhuTPJQdH4',\n",
              "  'updatedRange': \"'シート65'!A559\"}}"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### まんが王国 ランキング\n",
        "---"
      ],
      "metadata": {
        "id": "SXxB8idQUghG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google_colab_selenium as gs\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.common.by import By\n",
        "\n",
        "options = Options()\n",
        "options.add_argument(\"--headless\")\n",
        "\n",
        "print(\"connectiong to remote browser...\")\n",
        "driver = gs.Chrome(options=options)\n",
        "\n",
        "driver.get(\"https://comic.k-manga.jp/rank/\")\n",
        "\n",
        "kingmanga_data_to_insert = []\n",
        "ranking_item_wrap_list = driver.find_elements(\n",
        "    By.XPATH,\n",
        "    '//*[@id=\"contents\"]/section[2]/ul/li'\n",
        ")\n",
        "\n",
        "for ranking_item_wrap in ranking_item_wrap_list:\n",
        "  count = 0\n",
        "  manga_title = ranking_item_wrap.find_element(\n",
        "      By.XPATH,\n",
        "      \"./a/h2\",\n",
        "  ).text\n",
        "\n",
        "  manga_url = ranking_item_wrap.find_element(\n",
        "      By.XPATH,\n",
        "      \"./a\",\n",
        "  ).get_attribute(\"href\")\n",
        "  manga_title = check_duplicate(manga_title)\n",
        "  text = delete_unnecessary_words(text)\n",
        "  if manga_title[:5] in [item[:5] for item in duplication_set] and manga_title[-3:] in [item[-3:] for item in duplication_set]:\n",
        "    continue\n",
        "  print(f\"{manga_title} {manga_url}\")\n",
        "  kingmanga_data_to_insert.append([manga_title, manga_url, \"まんが王国ランキング\"])\n",
        "  duplication_set.add(manga_title)\n",
        "\n",
        "  count += 1\n",
        "  if count == 20:\n",
        "      break\n",
        "st.append_rows(values=kingmanga_data_to_insert)\n",
        "driver.quit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "pTldcD5iV82T",
        "outputId": "f872ee81-4b4b-45a4-8808-8f4fd2c8bc57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "connectiong to remote browser...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <div class=\"spinner-container\">\n",
              "                <div class=\"spinner\" id=\"65e44144-359f-4c13-9720-99f1824cb3d8-circle\"></div>\n",
              "                <div class=\"spinner-text\" id=\"65e44144-359f-4c13-9720-99f1824cb3d8-text\">Initializing Chromedriver</div>\n",
              "            </div>\n",
              "            <style>\n",
              "                @keyframes spin {\n",
              "                    from { transform: rotate(0deg); }\n",
              "                    to { transform: rotate(360deg); }\n",
              "                }\n",
              "\n",
              "                .spinner-container {\n",
              "                    display: flex;\n",
              "                    align-items: center;\n",
              "                    margin-bottom: 3px;\n",
              "                }\n",
              "\n",
              "                .spinner {\n",
              "                    border: 3px solid rgba(0, 0, 0, 0.1);\n",
              "                    border-left-color: lightblue;\n",
              "                    border-radius: 50%;\n",
              "                    width: 12px;\n",
              "                    height: 12px;\n",
              "                    animation: spin 1s linear infinite;\n",
              "                }\n",
              "\n",
              "                .spinner-text {\n",
              "                    padding-left: 6px;\n",
              "                }\n",
              "            </style>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            const element = document.getElementById(\"65e44144-359f-4c13-9720-99f1824cb3d8-circle\");\n",
              "            element.style.border = \"3px solid limegreen\";\n",
              "            element.style.animation = \"none\";\n",
              "\n",
              "            const text = document.getElementById(\"65e44144-359f-4c13-9720-99f1824cb3d8-text\");\n",
              "            text.innerText = \"Initialized Chromedriver\";\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### まんが王国 先行配信ランキング\n",
        "---"
      ],
      "metadata": {
        "id": "SRFyCWr8cnSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google_colab_selenium as gs\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.common.by import By\n",
        "\n",
        "options = Options()\n",
        "options.add_argument(\"--headless\")\n",
        "\n",
        "print(\"connectiong to remote browser...\")\n",
        "driver = gs.Chrome(options=options)\n",
        "\n",
        "driver.get(\"https://comic.k-manga.jp/pre\")\n",
        "kingmanga_ranking_data_to_insert = []\n",
        "\n",
        "ranking_item_wrap_list = driver.find_elements(\n",
        "    By.XPATH,\n",
        "    '//*[@id=\"contents\"]/section[2]/div[2]/div'\n",
        ")\n",
        "\n",
        "for ranking_item_wrap in ranking_item_wrap_list:\n",
        "\n",
        "  manga_title = ranking_item_wrap.find_element(\n",
        "      By.XPATH,\n",
        "      \"./a/p[2]\",\n",
        "  ).text\n",
        "\n",
        "  manga_url = ranking_item_wrap.find_element(\n",
        "      By.XPATH,\n",
        "      \"./a\",\n",
        "  ).get_attribute(\"href\")\n",
        "  manga_title = check_duplicate(manga_title)\n",
        "  manga_title = delete_unnecessary_words(manga_title)\n",
        "  if manga_title[:5] in [item[:5] for item in duplication_set] and manga_title[-3:] in [item[-3:] for item in duplication_set]:\n",
        "    continue\n",
        "  print(f\"{manga_title} {manga_url}\")\n",
        "  kingmanga_ranking_data_to_insert.append([manga_title, manga_url, \"まんが王国先行配信ランキング\"])\n",
        "  duplication_set.add(manga_title)\n",
        "\n",
        "st.append_rows(values=kingmanga_ranking_data_to_insert)\n",
        "driver.quit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "s2C5G03hco4m",
        "outputId": "3354b06e-c06f-4621-e2e9-cd663b100756"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "connectiong to remote browser...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <div class=\"spinner-container\">\n",
              "                <div class=\"spinner\" id=\"7433f427-19b8-4e82-9055-b788153d640b-circle\"></div>\n",
              "                <div class=\"spinner-text\" id=\"7433f427-19b8-4e82-9055-b788153d640b-text\">Initializing Chromedriver</div>\n",
              "            </div>\n",
              "            <style>\n",
              "                @keyframes spin {\n",
              "                    from { transform: rotate(0deg); }\n",
              "                    to { transform: rotate(360deg); }\n",
              "                }\n",
              "\n",
              "                .spinner-container {\n",
              "                    display: flex;\n",
              "                    align-items: center;\n",
              "                    margin-bottom: 3px;\n",
              "                }\n",
              "\n",
              "                .spinner {\n",
              "                    border: 3px solid rgba(0, 0, 0, 0.1);\n",
              "                    border-left-color: lightblue;\n",
              "                    border-radius: 50%;\n",
              "                    width: 12px;\n",
              "                    height: 12px;\n",
              "                    animation: spin 1s linear infinite;\n",
              "                }\n",
              "\n",
              "                .spinner-text {\n",
              "                    padding-left: 6px;\n",
              "                }\n",
              "            </style>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            const element = document.getElementById(\"7433f427-19b8-4e82-9055-b788153d640b-circle\");\n",
              "            element.style.border = \"3px solid limegreen\";\n",
              "            element.style.animation = \"none\";\n",
              "\n",
              "            const text = document.getElementById(\"7433f427-19b8-4e82-9055-b788153d640b-text\");\n",
              "            text.innerText = \"Initialized Chromedriver\";\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### めちゃコミックス 独占\n",
        "---\n"
      ],
      "metadata": {
        "id": "gtEjjg72oFlT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# スクレイピング対象の URL にリクエストを送り HTML を取得する\n",
        "res = requests.get('https://mechacomic.jp/books/exclusive_top')\n",
        "\n",
        "mecha_comi_list = []\n",
        "  # レスポンスの HTML から BeautifulSoup オブジェクトを作る\n",
        "soup = BeautifulSoup(res.text, 'html.parser')\n",
        "\n",
        "title = soup.select(f'body > div.pc.all > div > div.container_body.right.u-mb24 > section > section:nth-child(4) > h2')\n",
        "print(\"------\")\n",
        "print(\"【\"+ title[0].text.strip() + \"】\")\n",
        "\n",
        "elems = soup.select(f'#ec_exclusive_ad_slider_1 > span')\n",
        "\n",
        "# liの個数をカウントする\n",
        "target_element = soup.select('body > div.pc.all > div > div.container_body.right.u-mb24 > section > section:nth-of-type(4) > div > ul')\n",
        "new = soup.find(class_='p-exclusiveImage').find(\"ul\")\n",
        "li_count = 0\n",
        "for element in new.find_all(\"li\"):\n",
        "  li_count+=1\n",
        "\n",
        "for i in range(1, li_count * 2, 2):\n",
        "  elems = soup.select(f'#ec_exclusive_ad_slider_{i}')\n",
        "  title_elems = soup.select(f'#ec_exclusive_ad_slider_{i} > span')\n",
        "  if elems:\n",
        "    book_title = title_elems[0].text.strip()\n",
        "    link = elems[0]['href']\n",
        "    full_path = \"https://mechacomic.jp\" + link\n",
        "    book_title = check_duplicate(book_title)\n",
        "    book_title = delete_unnecessary_words(book_title)\n",
        "    if book_title[:5] in [item[:5] for item in duplication_set] and book_title[-3:] in [item[-3:] for item in duplication_set]:\n",
        "      continue\n",
        "    print(book_title, full_path)\n",
        "    duplication_set.add(book_title)\n",
        "    mecha_comi_list.append([book_title, full_path, \"めちゃコミ独占\"])\n",
        "\n",
        "\n",
        "mechacomic_dict = {\"おすすめ無料連載\" : \"#ec_exclusive_top_free_daily_\", \"おすすめ期間限定無料\" : \"#ec_exclusive_top_free_discount_\", \"あなたにおすすめ\" : \"#ec_exclusive_top_recli_\", \"人気作品ランキング(少女・女性)\" : \"#ec_exclusive_top_ranking_girl_\", \"人気作品ランキング(少年・青年)\" : \"#ec_exclusive_top_ranking_boy_\", \"新着入荷\" : \"#ec_exclusive_top_recent_\", \"おすすめレーベル\" : \"#ec_exclusive_fufu_\"}\n",
        "\n",
        "def get_mechacomic_books(count):\n",
        "  title_element = soup.select(f'body > div.pc.all > div > div.container_body.right.u-mb24 > section > section:nth-of-type({count}) > a > h2')\n",
        "  title = title_element[0].text.strip()\n",
        "  mechacomic_class = mechacomic_dict[title]\n",
        "  print(\"------\")\n",
        "  print(\"【\"+ title + \"】\")\n",
        "\n",
        "  target_element = soup.select(f'body > div.pc.all > div > div.container_body.right.u-mb24 > section > section:nth-of-type({count}) > ul')\n",
        "  ul_element = target_element[0] if target_element else None\n",
        "  if ul_element:\n",
        "      li_elements = ul_element.find_all('li')\n",
        "      li_count = len(li_elements)\n",
        "\n",
        "  for i in range(1, li_count * 2, 2):\n",
        "    elems = soup.select(f'{mechacomic_class}{i}')\n",
        "    title_elems = soup.select(f'{mechacomic_class}{i} > span')\n",
        "    if elems:\n",
        "      book_title = title_elems[0].text.strip()\n",
        "      link = elems[0]['href']\n",
        "      full_path = \"https://mechacomic.jp\" + link\n",
        "      book_title = check_duplicate(book_title)\n",
        "      book_title = delete_unnecessary_words(book_title)\n",
        "      if book_title[:5] in [item[:5] for item in duplication_set] and book_title[-3:] in [item[-3:] for item in duplication_set]:\n",
        "        continue\n",
        "      print(book_title, full_path)\n",
        "      mecha_comi_list.append([book_title, full_path, \"めちゃコミ独占\"])\n",
        "      duplication_set.add(book_title)\n",
        "\n",
        "def get_mechacomic_books2(count):\n",
        "  title_element = soup.select(f'body > div.pc.all > div > div.container_body.right.u-mb24 > section > section:nth-of-type({count}) > h2')\n",
        "  title = title_element[0].text.strip()\n",
        "  mechacomic_class = mechacomic_dict[title]\n",
        "  print(\"------\")\n",
        "  print(\"【\"+ title + \"】\")\n",
        "\n",
        "  target_element = soup.select(f'body > div.pc.all > div > div.container_body.right.u-mb24 > section > section:nth-of-type({count}) > div > ul')\n",
        "\n",
        "  ul_element = target_element[0] if target_element else None\n",
        "  if ul_element:\n",
        "      li_elements = ul_element.find_all('li')\n",
        "      li_count = len(li_elements)\n",
        "\n",
        "  for i in range(1, li_count * 2, 2):\n",
        "    elems = soup.select(f'{mechacomic_class}{i}')\n",
        "    title_elems = soup.select(f'{mechacomic_class}{i} > span')\n",
        "    if elems:\n",
        "      book_title = title_elems[0].text.strip()\n",
        "      link = elems[0]['href']\n",
        "      full_path = \"https://mechacomic.jp\" + link\n",
        "      book_title = check_duplicate(book_title)\n",
        "      book_title = delete_unnecessary_words(book_title)\n",
        "      if book_title[:5] in [item[:5] for item in duplication_set] and book_title[-3:] in [item[-3:] for item in duplication_set]:\n",
        "        continue\n",
        "      print(book_title, full_path)\n",
        "      mecha_comi_list.append([book_title, full_path, \"めちゃコミ独占\"])\n",
        "      duplication_set.add(book_title)\n",
        "\n",
        "def get_mechacomic_books3(count):\n",
        "  title_element = soup.select(f'body > div.pc.all > div > div.container_body.right.u-mb24 > section > section:nth-of-type(7) > a > h2')\n",
        "  title = title_element[0].text.strip()\n",
        "  mechacomic_class = mechacomic_dict[title]\n",
        "  print(\"------\")\n",
        "  print(\"【\"+ title + \"】\")\n",
        "\n",
        "  target_element = soup.select(f'body > div.pc.all > div > div.container_body.right.u-mb24 > section > section:nth-of-type({count}) > div > ul')\n",
        "\n",
        "  ul_element = target_element[0] if target_element else None\n",
        "  if ul_element:\n",
        "      li_elements = ul_element.find_all('li')\n",
        "      li_count = len(li_elements)\n",
        "\n",
        "  for i in range(1, li_count * 2, 2):\n",
        "    elems = soup.select(f'{mechacomic_class}{i}')\n",
        "    title_elems = soup.select(f'{mechacomic_class}{i} > span')\n",
        "    if elems:\n",
        "      book_title = title_elems[0].text.strip()\n",
        "      link = elems[0]['href']\n",
        "      full_path = \"https://mechacomic.jp\" + link\n",
        "      book_title = check_duplicate(book_title)\n",
        "      book_title = delete_unnecessary_words(book_title)\n",
        "      if book_title[:5] in [item[:5] for item in duplication_set] and book_title[-3:] in [item[-3:] for item in duplication_set]:\n",
        "        continue\n",
        "      print(book_title, full_path)\n",
        "      mecha_comi_list.append([book_title, full_path, \"めちゃコミ独占\"])\n",
        "      duplication_set.add(book_title)\n",
        "\n",
        "def get_mechacomic_books4(count):\n",
        "  title_element = soup.select(f'body > div.pc.all > div > div.container_body.right.u-mb24 > section > section:nth-of-type({count}) > h2')\n",
        "  title = title_element[0].text.strip()\n",
        "  mechacomic_class = mechacomic_dict[title]\n",
        "  print(\"------\")\n",
        "  print(\"【\"+ title + \"】\")\n",
        "\n",
        "  target_element = soup.select(f'body > div.pc.all > div > div.container_body.right.u-mb24 > section > section:nth-of-type(8) > section:nth-of-type(2) > div > ul')\n",
        "\n",
        "  ul_element = target_element[0] if target_element else None\n",
        "  if ul_element:\n",
        "      li_elements = ul_element.find_all('li')\n",
        "      li_count = len(li_elements)\n",
        "\n",
        "  for i in range(1, li_count * 2, 2):\n",
        "    elems = soup.select(f'{mechacomic_class}{i}')\n",
        "    title_elems = soup.select(f'{mechacomic_class}{i} > span')\n",
        "    if elems:\n",
        "      book_title = title_elems[0].text.strip()\n",
        "      link = elems[0]['href']\n",
        "      full_path = \"https://mechacomic.jp\" + link\n",
        "      book_title = check_duplicate(book_title)\n",
        "      book_title = delete_unnecessary_words(book_title)\n",
        "      if book_title[:5] in [item[:5] for item in duplication_set] and book_title[-3:] in [item[-3:] for item in duplication_set]:\n",
        "        continue\n",
        "      print(book_title, full_path)\n",
        "      mecha_comi_list.append([book_title, full_path, \"めちゃコミ独占\"+ \"【\"+ title + \"】\"])\n",
        "      duplication_set.add(book_title)\n",
        "\n",
        "get_mechacomic_books(2)\n",
        "get_mechacomic_books(3)\n",
        "get_mechacomic_books2(5)\n",
        "get_mechacomic_books2(6)\n",
        "get_mechacomic_books3(7)\n",
        "get_mechacomic_books4(8)\n",
        "st.append_rows(values=mecha_comi_list)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-wRVAirp57e",
        "outputId": "188738a2-bcc7-4578-c9d5-5a0711ecf89e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------\n",
            "【いま話題の作品】\n",
            "------\n",
            "【おすすめ無料連載】\n",
            "------\n",
            "【おすすめ期間限定無料】\n",
            "------\n",
            "【人気作品ランキング(少女・女性)】\n",
            "------\n",
            "【人気作品ランキング(少年・青年)】\n",
            "------\n",
            "【新着入荷】\n",
            "------\n",
            "【おすすめレーベル】\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'spreadsheetId': '1RiLchx4pkQ_vdngW3UIG49xuhoZEThM4rAhuTPJQdH4',\n",
              " 'tableRange': \"'シート65'!A1:C558\",\n",
              " 'updates': {'spreadsheetId': '1RiLchx4pkQ_vdngW3UIG49xuhoZEThM4rAhuTPJQdH4',\n",
              "  'updatedRange': \"'シート65'!A559\"}}"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ピッコマ ランキング\n",
        "---"
      ],
      "metadata": {
        "id": "EUaWVIwRNwNC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "piccoma_list = []\n",
        "classification_dict = {\"総合\": \"0\",\"ファンタジー\": \"2\",\"恋愛\": \"1\",\"アクション\": \"5\",\"ドラマ\": \"3\",\"ホラー・ミステリー\": \"7\",\"裏社会・アングラ\": \"9\",\"スポーツ\": \"6\",\"グルメ\": \"10\",\"日常\": \"4\",\"TL\": \"13\",\"BL\": \"14\",}\n",
        "\n",
        "\n",
        "def get_piccoma_books(classification):\n",
        "  page_query = classification_dict[classification]\n",
        "  # スクレイピング対象の URL にリクエストを送り HTML を取得する\n",
        "  res = requests.get(f'https://piccoma.com/web/ranking/K/P/{page_query}')\n",
        "  # レスポンスの HTML から BeautifulSoup オブジェクトを作る\n",
        "  soup = BeautifulSoup(res.text, 'html.parser')\n",
        "  print(\"------\")\n",
        "  print(\"【\"+ classification + \"】\")\n",
        "  for i in range(1,11):\n",
        "    title_elems = soup.select(f'#js_contentBody > section > ul > li:nth-of-type({i}) > a > div > div.PCM-l_rankingProduct_info > div > div.PCM-rankingProduct_tdata > div.PCM-rankingProduct_title > p')\n",
        "    link_elems = soup.select(f'#js_contentBody > section > ul > li:nth-child({i}) > a')\n",
        "    link = link_elems[0]['href']\n",
        "    full_path = \"https://piccoma.com/\" + link\n",
        "    title = title_elems[0].text.strip()\n",
        "    title = check_duplicate(title)\n",
        "    title = delete_unnecessary_words(title)\n",
        "    if title[:5] in [item[:5] for item in duplication_set] and title[-3:] in [item[-3:] for item in duplication_set]:\n",
        "      continue\n",
        "    print(title, full_path)\n",
        "    piccoma_list.append([title, full_path, \"ピッコマランキング\"+ \"【\"+ classification + \"】\"])\n",
        "    duplication_set.add(title)\n",
        "\n",
        "get_piccoma_books(\"総合\")\n",
        "get_piccoma_books(\"ファンタジー\")\n",
        "get_piccoma_books(\"恋愛\")\n",
        "get_piccoma_books(\"アクション\")\n",
        "get_piccoma_books(\"ドラマ\")\n",
        "get_piccoma_books(\"ホラー・ミステリー\")\n",
        "get_piccoma_books(\"裏社会・アングラ\")\n",
        "get_piccoma_books(\"スポーツ\")\n",
        "get_piccoma_books(\"グルメ\")\n",
        "get_piccoma_books(\"日常\")\n",
        "get_piccoma_books(\"TL\")\n",
        "get_piccoma_books(\"BL\")\n",
        "\n",
        "st.append_rows(values=piccoma_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ckm4yQxjjZ9Q",
        "outputId": "da4c7022-1546-4302-9d5c-207fb197b646"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------\n",
            "【総合】\n",
            "------\n",
            "【ファンタジー】\n",
            "------\n",
            "【恋愛】\n",
            "------\n",
            "【アクション】\n",
            "------\n",
            "【ドラマ】\n",
            "------\n",
            "【ホラー・ミステリー】\n",
            "------\n",
            "【裏社会・アングラ】\n",
            "------\n",
            "【スポーツ】\n",
            "------\n",
            "【グルメ】\n",
            "------\n",
            "【日常】\n",
            "------\n",
            "【TL】\n",
            "------\n",
            "【BL】\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'spreadsheetId': '1RiLchx4pkQ_vdngW3UIG49xuhoZEThM4rAhuTPJQdH4',\n",
              " 'tableRange': \"'シート65'!A1:C558\",\n",
              " 'updates': {'spreadsheetId': '1RiLchx4pkQ_vdngW3UIG49xuhoZEThM4rAhuTPJQdH4',\n",
              "  'updatedRange': \"'シート65'!A559\"}}"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ここまでの手順が完了したら、kw・発注管理シートの\"スクレイピング結果\"シートを確認し、漫画やurlが記載されていることを確認してください。"
      ],
      "metadata": {
        "id": "lSErBWQWTLBD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 発注管理シートの電子書籍C列と比較をし、被りがなければシートに追加する\n",
        "---"
      ],
      "metadata": {
        "id": "5lmGeRDqTRIi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "全てのセル実行が完了してから動かしてください。"
      ],
      "metadata": {
        "id": "cxU3U_n6TeeR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 事前準備\n",
        "Google Sheets APIへの書き込みリクエストの制限を超えるため、リスト系は作成しておく"
      ],
      "metadata": {
        "id": "RZ4fbsdgowve"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# スプレッドシートとの連携\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import gspread\n",
        "from google.auth import default\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "\n",
        "# 発注管理シート\n",
        "url = \"https://docs.google.com/spreadsheets/d/1RiLchx4pkQ_vdngW3UIG49xuhoZEThM4rAhuTPJQdH4/edit#gid=1338119606\"\n",
        "ss = gc.open_by_url(url)\n",
        "# シートを特定する（書き出し用）\n",
        "st = ss.worksheet(\"スクレイピング結果\")\n",
        "\n",
        "# シートを特定する（電子書籍）\n",
        "el_st = ss.worksheet(\"電子書籍\")"
      ],
      "metadata": {
        "id": "RoLNXNyt_0Ne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# C列の値を取得してリストに格納\n",
        "c_column_values = el_st.col_values(3)\n",
        "# A列とB列の値を取得\n",
        "a_values = st.col_values(1)[1:]\n",
        "b_values = st.col_values(2)[1:]\n",
        "c_values = st.col_values(3)[1:]\n",
        "\n",
        "# 対応する辞書を作成\n",
        "corresponding_dict = dict(zip(a_values, b_values))\n",
        "corresponding_dict2 = dict(zip(a_values, c_values))\n",
        "\n",
        "last_row = len(el_st.col_values(3)) + 1"
      ],
      "metadata": {
        "id": "VZ3WrqIVov5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 被りチェック -> 発注管理シート書き込み"
      ],
      "metadata": {
        "id": "WKrQ0aDr_8KU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 一括で更新するデータを作成\n",
        "service_dict = {\"https://www.cmoa.jp\":\"コミックシーモア\", \"https://booklive.jp\":\"ブックライブ\", \"https://renta.papy.co.jp\":\"renta\", \"https://comic.k-manga.jp\":\"まんが王国\", \"https://mechacomic.jp\":\"めちゃコミック\", \"https://piccoma.com\" : \"ピッコマ\"}\n",
        "\n",
        "batch_data = []\n",
        "roop_counter = 0\n",
        "# 最初の5文字が一緒 かつ 後ろの3文字がc列のキーワードに含まれる\n",
        "for key, value in corresponding_dict.items():\n",
        "    # c_column_valuesリストの各要素の最初の5文字と比較\n",
        "    if any(key[:5] == c_prefix[:5] and key[-3:] in c_prefix for c_prefix in c_column_values):\n",
        "        print(key)\n",
        "        continue\n",
        "    if key not in c_column_values:\n",
        "        insert_row = last_row + roop_counter\n",
        "        batch_data.append({\"range\": f\"C{insert_row}\", \"values\": [[key]]})\n",
        "        batch_data.append({\"range\": f\"N{insert_row}\", \"values\": [[\"新規\"]]})\n",
        "        batch_data.append({\"range\": f\"T{insert_row}\", \"values\": [[value]]})\n",
        "        url_prefix = next((service_url for service_url in service_dict.keys() if value.startswith(service_url)), None)\n",
        "        if url_prefix:\n",
        "            # service_name = service_dict[url_prefix]\n",
        "            memo = corresponding_dict2[key]\n",
        "            # el_st.update_cell(insert_row, 10, service_name + memo)\n",
        "            batch_data.append({\"range\": f\"J{insert_row}\", \"values\": [[memo]]})\n",
        "        roop_counter += 1\n",
        "\n",
        "# 一括で更新\n",
        "el_st.batch_update(batch_data)\n",
        "\n",
        "# 全てのkw洗い出しが完了したら、スクレイピング結果のシートを白紙に戻す\n",
        "delete_row = len(st.col_values(1))\n",
        "print(delete_row)\n",
        "# 行を削除する\n",
        "st.delete_rows(2, delete_row + 1)"
      ],
      "metadata": {
        "id": "Az_7QYruop03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "714b0500-08f1-43a0-d012-d53686cdff81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "赤ちゃんに転生した話\n"
          ]
        }
      ]
    }
  ]
}